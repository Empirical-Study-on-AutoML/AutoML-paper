# -*- coding: utf-8 -*-
"""Dec 5_data cleaning in order to get the unique code path.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e7AdQiecYMNd3h7F_fYfKwJErfChXKpd
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df1=pd.read_csv('/content/drive/MyDrive/12th meeting/input_data/Dec1_split1_data_writer_path_part_1.csv')
df2=pd.read_csv('/content/drive/MyDrive/12th meeting/input_data/Dec1_split1_data_writer_path_part_2.csv')
df3=pd.read_csv('/content/drive/MyDrive/12th meeting/input_data/Dec1_split1_data_writer_path_part_11.csv')
df4=pd.read_csv('/content/drive/MyDrive/12th meeting/input_data/Dec1_split1_data_writer_path_part_22.csv')

df=pd.concat([df1, df2,df3,df4], ignore_index=True)

df=df[df["repo_name"].str.contains("assignment")==False]
df=df[df["repo_name"].str.contains("Assignment")==False]
df=df[df["repo_name"].str.contains("book")==False]
df=df[df["repo_name"].str.contains("Book")==False]
df=df[df["repo_name"].str.contains("chapter")==False]
df=df[df["repo_name"].str.contains("Chapter")==False]
df=df[df["repo_name"].str.contains("tutorial")==False]
df=df[df["repo_name"].str.contains("Tutorial")==False]
df=df[df["repo_name"].str.contains("course")==False]
df=df[df["repo_name"].str.contains("Course")==False]

df

len(df.file_sha.unique())

df = df.drop_duplicates(subset=['file_sha'])
df

list_of_forked_projects=['Mr-memorandum/Gauss','louzounlab/microbiome','andronikmk/toxic-content-monitoring','JDRomano2/tpot-nn','limiteinductive/covsco','UofTCoders/studyGroup','IMFardz/AngryTops','dsindiavscovid/covid19-india','PKU-DAIR/open-box','sergeyf/SmallDataBenchmarks','Vooban/Hyperopt-Keras-CNN-CIFAR-100','braceal/molecules','Owlmanandy/CPRHD_WNV_GI','hpi-dhc/trec-pm','codalab/competition-examples','JULIELab/trec-pm','OCHA-DAP/pa-ocha-bucky','KasperEinarson/Advanced-machine-learning','Shubham-Kr-Shaw/Project_21','simo955/Predicting_cars_speed','alinaciuysal/OEDA','iliasger/RTX','mila-iqia/orion.algo.skopt','upb-lea/deep-pmsm','ketrint/galaxymass','Azarodnyuk/galaxymass','HSE-LAMBDA/MLatURL2020','zhangxiaoyu11/XOmiVAE','raspstephan/uwnet','rrosajp/catchuptvandmore-test','Mrvishal2k2/youtube-dl','animelover1984/youtube-dl','automl/fanova','automl/pysmac','agoose77/hive2','LiuLab-CSRC/spipy','jdragojevic/unisubs','appsembler/unisubs','kovshenin/unisubs','honza/unisubs']

df2 = df[~df['repo_name'].isin(list_of_forked_projects)]

df2

output_path="/content/drive/MyDrive/12th meeting/input_data/"
df2.to_csv(output_path+"merged_split_data_writer_path_WITHOUT_DUPLICATED_SHA_AND_REMOVED_FORKED_PROJECTS.csv")